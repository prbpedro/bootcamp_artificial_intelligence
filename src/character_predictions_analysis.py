import warnings
# sklearn é uma das lib mais utilizadas em ML, ela contém, além dos
from sklearn import datasets
# datasets, várias outras funções úteis para a análise de dados
# essa lib será sua amiga durante toda sua carreira
# importa a lib Pandas. Essa lib é utilizada para lidar com dataframes (TABELAS)
import pandas as pd
# de forma mais amigável.
# esse método é utilizado para dividir o
from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict
# conjunto de dados em grupos de treinamento e test
from sklearn.svm import SVC  # importa o algoritmo svm para ser utilizado
from sklearn import tree         # importa o algoritmo arvore de decisão
# importa o algoritmo de regressão logística
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_absolute_error  # utilizada para o calculo do MAE
from sklearn.metrics import mean_squared_error  # utilizada para o calculo do MSE
from sklearn.metrics import r2_score  # utilizada para o calculo do R2
# utilizada para as métricas de comparação entre os métodos
from sklearn import metrics
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm

pd.set_option('display.max_colwidth', None)

pd.set_option('display.max_columns', None)

# realiza a leitura do dataset
got_dataset = pd.read_csv(
    '/home/prbpedro/Development/repositories/github/bootcamp_artificial_intelligence/src/input/game-of-thrones/character-predictions.csv')

got_dataset.info()  # conhecendo o dataset

print(got_dataset.describe())  # conhecendo o dataset

print(got_dataset.head()) # mostrando o dataset

nans = got_dataset.isna().sum()  # contando a quantidade de valores nulos
nans[nans > 0]
print(nans)

# Tamanho do dataset
len(got_dataset)

# analisando os dados nulos
# possível erro no nosso dataset (média negativa para a idade?)
print(got_dataset["age"].mean())

# realizando uma maior análise do dataset
print(got_dataset["name"][got_dataset["age"] < 0])
print(got_dataset['age'][got_dataset['age'] < 0])

# substituindo os valores negativos
got_dataset.loc[1684, "age"] = 25.0
got_dataset.loc[1868, "age"] = 0.0

print(got_dataset["age"].mean())  # verificando, novamente, a idade

# trabalhando com dados nulos
# substituindo os valores nulos pela média da coluna
got_dataset["age"].fillna(got_dataset["age"].mean(), inplace=True)
# preenchendo os valores nulos da coluna cultura com uma string nula
got_dataset["culture"].fillna("", inplace=True)

# preenchendo os demais valores com -1
got_dataset.fillna(value=-1, inplace=True)

# realizando o boxplot
got_dataset.boxplot(['alive', 'popularity'])

# analisando a "mortalidade" dos personagens
warnings.filterwarnings('ignore')
f, ax = plt.subplots(2, 2, figsize=(17, 15))
sns.violinplot("isPopular", "isNoble", hue="isAlive",
               data=got_dataset, split=True, ax=ax[0, 0])
ax[0, 0].set_title('Noble and Popular vs Mortality')
ax[0, 0].set_yticks(range(2))

sns.violinplot("isPopular", "male", hue="isAlive",
               data=got_dataset, split=True, ax=ax[0, 1])
ax[0, 1].set_title('Male and Popular vs Mortality')
ax[0, 1].set_yticks(range(2))

sns.violinplot("isPopular", "isMarried", hue="isAlive",
               data=got_dataset, split=True, ax=ax[1, 0])
ax[1, 0].set_title('Married and Popular vs Mortality')
ax[1, 0].set_yticks(range(2))


sns.violinplot("isPopular", "book1", hue="isAlive",
               data=got_dataset, split=True, ax=ax[1, 1])
ax[1, 1].set_title('Book_1 and Popular vs Mortality')
ax[1, 1].set_yticks(range(2))


plt.show()

# Retirando algumas colunas
drop = ["S.No", "pred", "alive", "plod", "name", "isAlive", "DateoFdeath"]
got_dataset.drop(drop, inplace=True, axis=1)

# Salvando uma cópia do dataset para aplicar o hotencoder
got_dataset_2 = got_dataset.copy(deep=True)

# transformando os dados categóricos em one-hot-encoder
got_dataset = pd.get_dummies(got_dataset)

got_dataset.head()

# Separando o dataset entre entradas e saídas
x = got_dataset.iloc[:, 1:].values
y = got_dataset.iloc[:, 0].values

# aplicando o modelo de validação cruzada
# divide o dataset entre 5 diferentes grupos
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# construindo os modelos de classificação
modelos = [LogisticRegression(solver='liblinear'), RandomForestClassifier(n_estimators=400, random_state=42),
           DecisionTreeClassifier(random_state=42), svm.SVC(
               kernel='rbf', gamma='scale', random_state=42),
           KNeighborsClassifier()]

# utilizando a validação cruzada
mean = []
std = []
for model in modelos:
    result = cross_val_score(model, x, y, cv=kfold,
                             scoring="accuracy", n_jobs=-1)
    mean.append(result)
    std.append(result)

classificadores = ['Regressão Logística',
                   'Random Forest', 'Árvore de Decisão', 'SVM', 'KNN']

plt.figure(figsize=(10, 10))
for i in range(len(mean)):
    sns.distplot(mean[i], hist=False, kde_kws={"shade": True})

plt.title("Distribuição de cada um dos classificadores", fontsize=15)
plt.legend(classificadores)
plt.xlabel("Acurácia", labelpad=20)
plt.yticks([])

plt.show()

"""**Realizando a previsão dos classificadores**

** Quais algoritmos escollher?**
"""

# Dividindo o dataset entre treinamento 80% e teste 20%
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y,
                                                    shuffle=True, random_state=42)

# escolhendo o svm e a floresta randomica
svm_clf = svm.SVC(C=0.9, gamma=0.1, kernel='rbf',
                  probability=True, random_state=42)
rf_clf = RandomForestClassifier(n_estimators=400, n_jobs=-1, random_state=42)

# Treina os modelos
svm_clf.fit(x_train, y_train)
rf_clf.fit(x_train, y_train)

# obtém as probabilidades previstas
svm_prob = svm_clf.predict_proba(x_test)
rf_prob = rf_clf.predict_proba(x_test)

# Valores reais
svm_preds = np.argmax(svm_prob, axis=1)
rf_preds = np.argmax(rf_prob, axis=1)

# analisando os modelos
cm = metrics.confusion_matrix(y_test, svm_preds)
cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
cm2 = metrics.confusion_matrix(y_test, rf_preds)
cm2 = cm2.astype('float') / cm2.sum(axis=1)[:, np.newaxis]

classes = ["Morto", "Vivo"]
f, ax = plt.subplots(1, 2, figsize=(15, 5))
ax[0].set_title("SVM", fontsize=15.)
sns.heatmap(pd.DataFrame(cm, index=classes, columns=classes),
            cmap='winter', annot=True, fmt='.2f', ax=ax[0]).set(xlabel="Previsao", ylabel="Valor Real")

ax[1].set_title("Random Forest", fontsize=15.)
sns.heatmap(pd.DataFrame(cm2, index=classes, columns=classes),
            cmap='winter', annot=True, fmt='.2f', ax=ax[1]).set(xlabel="Previsao",
                                                                ylabel="Valor Real")
