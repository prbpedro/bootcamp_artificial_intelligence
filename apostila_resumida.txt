Módulo 1 - Fundamentos 

	##### Capítulo 1 - Introdução

		Formas de aprendizado
			1) Supervisionado:
				São dadas entradas e respostas, classes conhecidas previamente
				Útil para:
					Classificação
					Regressão
					Estimativa de probabilidade condicional
			2) Não Supervisionado:
				São dadas somente as entradas, classes não conhecidas previamente. Algoritmos autoditadas.
				Melhores para números grandes de possibilidades de entradas
				Útil para:
					Reconhecimento facial
					Manuscritos
					Predição de ações
					Gerenciamento de riscos na área das finanças
					Predição de tráfego
					Jogos
			3) Por Reforço:
				Recompensas e penalidades são dadas  cada execução de ação do agente.
				O agente deve sempre tomar decisões a maximar as recompensas. Z(r)

		Overfitting e Underfitting
			Overfitting (Sobreajuste)
				O modelo estatístico se ajusta de forma excessiva aos dados de treinamento.
				O algoritmo não generaliza de forma necessária.
				Baixa taxa de erros em treinamento e alta em testes.
				Possivel motivo:
					Conjunto muito grande de exemplos com pequena variação entre as classes.
			Underfitting (Subajuste)
				Alta taxa de erro na aprendizagem/treinamento e nos testes.	
				Problemas no próprio conjunto de dados de treinamento.
			O ideal é ter um modelo balenceado que eja fléxivel o sificiente para capturar a forma de curva da função f e que não seja exatamente igual a esta.

		Dimensionamento e definição de problemas
			A maldição da dimensionalidade é o termo que se refere a vários fenômenos que surgem na análise de dados m espaços com muitas dimensões (atributos). Um grande número de atributos tende a gerar informação rendundante e isso tende a prejudicar o sitema.
			Os objetos é um valor exponencial em relação as possibilidades de cada atributo deste. Um objeto com 10 atributos com 5 possibilidades cadagera um objeto de 5**10 possibilidades.
			Nos espaços com muitas dimensões as amostras se tornam esparsas e pouco similares, ficando distantes umas das outras.
			A redução da dimensionalidade melhora a eficácia dos algoritmos, reduz o tamanho da amostra, simplifica o modelo e melhora a visualização dos resultados. Deve-se utilizar um número pequeno de atributos, selecionados adequadamente ou criados por agragação de outros atributos ou transformação de dados.

		Projetando um sistema de aprendizagem
			Um programa de computador aprende a partir de uma experiência com uma classe de tarefas e uma medidade de desempenho.
			Etapas do projeto:
				1) Escolher uma experiência de treinamento para o sistema
					Tipo de e o grau de controle da sequencia de treinamento (Formas de aprendizado).
					Representa a distribuição de exemplos usados no treinamento.
				2) Escolher uma função objetivo.
					O que será aprendido. Como este conhecimento será utilizado.
				3) Escolher uma representação da função objetivo
					Programa de aprendizado (redes neurais, funções polinominais, coleção de regras, etc.).
				4) Escolher um algoritmo para a função de aproximação

		Pré-processamento e extração de características
			Definição:
				A característica é um atributo utilizado na descrição de um padrão, objeto ou situação. Devem ser discriminantes e invariantes, e os objetos devem ser conhecidos independentemente de sua rotação, translação, escala, etc..
				Qualquer medida que se possa extrair do objeto, seja simbólica, numérica contínua (intervalo ou união de números reais), numérica discreta(resultados possíveis é finito ou enumerável) ou numérica binária (booleana).
			Extração de características
				Objetivo:
					Caracterizar objetos verificando atributos que são similares para objetos da mesma classe e bastante diferente de objetos de outras classes.
			Pré-processamento:
				Objetivo:
					Preencher dados auzentes, remover ruídos (valores absurdos) e resolver inconsistências

	##### Capítulo 2 - Técnicas de aprendizado de máquina

		Classificação
			Objetivo:
				Contruir um modelo que seja capaz de classificar automaticamente novos objetos baseado em suas características (atributos) a partir do treinamento do algoritimo com uma base de objetos já classificados.
			Técnica de aprendizado supervisionado.
			Utilização:
				Classificação de riscos
				Classificação de emails como SPAM
				Separação de imagens
				Diagnostico de doenças baseado em sintomas
			Algorítimos (Outros também podem ser utilizados):
				Árvores de decisão
				KNN
				Redes neurais
				naive Bayes
				SVM

		Agrupamento (Clusters)
			Objetivo:
				Colocar em um mesmo grupo (Cluster) os objetos que sejam similares de acordo com algum critério pré-determinado.
			A divisão acontece de acordo com um tipo de relacionamento de similaridade.		
			As classes podem não ser conhecidas.
			Cada agrupamento (cluster) é exclusivo.
			Cada instância pertence a apenas um agrupamento (Cluster) ou possui a probabilidade percentual de pertencer a cada grupo.
			Algoritmo mais comum K-médias.
			Utilização:
				Identificação de clientes similares para maior assertividade no oferecimento de produtos
				Agrupamento de pacientes com os mesmos sintomas
				Identificação de público alvo ou segmento de mercado para campanha de marketing
				Classificação de documentos
				Qualquer aplicação com grandes quantidades de dados.

		Regressão
			Objetivo:
				Retornar previsões de valores numéricos a partir da análise de um conjunto de caracteristicas pré-determinadas e a relação destas com saídas numéricas. Estabelecer a relação entre um conjunto de dados de entrada e uma saída numérica,
			Utilização:
				Determinar preço de venda
				Prever quantidade de vendas baseado em resultados anteriores
				Previsão do tempo
				Previsçao do comportamento da bolsa de valores
			Regressão linear:
				Equação usada para determinar o valor estimado de uma variável y, dados os valores de algumas variáveis x.
			Regressão não linear:
				Os dados observacionais são limitados por uma função que é a combinação não linear dos parâmetros do modelo e depende de uma ou mais variáveis independentes. 
				Os dados são ajustados por um método que realiza aproximações sucessivas.

		Reconhecimento de padrões
			Objetivo:
				Classificar objetos em um número de categorias ou classes.
				Obserrvar os dados brutos e tomar uma ação baseada na categoria de um padrão.
			Utilização:
				Identificação de suspeitos criminais por reconhecimento facial ou impressão digital
				Reconhecimento de palavra contruída em uma escrita cursiva
				Reconhecimento de caracteres
				Classificação de células em análises laboratoriais
				Contágem de particulas de matéria
			Etapas do funcionamento:
				1) O algoritmo recebe um objeto desconhecido
				2) Um sensor faz a extração de suas características
				3) O objeto é classificado em uma das possíveis classes
			Pode-se atribuir um padrão a um conjunto desconhecido de classes de padrões (Cluster) ou identificar um padrão como membro de um conjunto de oadrões (Classificação)

		Sistemas de recomendação
			Objetivo:
				Auxiliar indivíduos a identificarem conteúdos de interesse em um conjunto de opções.
				Analisar os dados de um problema e extrairinformações úteis para futuras predições.
			Utilização:
				Experências de usuários.
			Para o funcionamento é necessário:
				1) Informações sobre as preferências dos usuários.
				2) Método que determina se um dado item é interessante para um usuário
			Tipos:
				Explícita: O usuário indica espontaneamente o que é importante para ele
				Implícita: O próprio sistema realiza ações baseadas em algumas características (de utilização, perfil, etc.) do usuário.
			Filtragem colaborativa
				Processo de filtrar  informação ou padrões usando técnicas que envolvem a colaboração de múltiplos agentes, pontos de vistas, fontes de dados, etc.
				Funciona a partir de uma base de dados de preferência de usuários. Novos usuários são comparados a esta base para encontrar os que possuem características similares.

		Processamento e mineração de textos
			Processo de descoberta do conhecimento que aplica algoritimos que processam textos e identificam informações úteis e implícitas.
			As informções não podem ser recuperadas usando métodos tradicionais pois geralmente são armazenadas no formato não estruturado.
			Objetivo:
				Contribuir com a busca específica em documentos, análise quantitativa e qualitativa de grandes volumes de dados e melhor compreensão de textos disponíveis em documentos
			Etapas:
				1) Coleta
					Formação da base de conhecimento ou corpus
					Robôs de Crawling atuando em qualquer ambiente
				2) Preparação dos dados
					Processamento de linguagem natural (PLN)
				3) Indexação
					Objetivo: Acesso rápido, busca.
					Recuperação de informação (IR)
				4) Mineração
					Calcula interferências e extração de conhecimento.
					Mineração de dados (DM)
				5) Análise
					Análise humana. Navegação.
					Leitura e interpretação dos dados.
			Utilização:
				Web Crawler
				Análise de sentimento
				Inteligência competitiva
				Suporte e atendimento ao usuário
				Área do direito
				Medicina

		Análise de sentimentos
			Objetivo: 
				Identificar o sentimento que os usuários presentam a respeto de uma entidade de interesse.
			Permitir que um usuário obtenha um relatório contendo o que as pessoas andam dizendo sobre algo, de forma compilada (sem precisar encontrar e ler as informações).
			Gera um termômetro de sentimentos sobre um determinado assunto.
			Utilização:
				Reputação de empresas
				Aceitação de produtos
			Dificuldades:
				Sentenças sintaticamente mal formuladas.
				Distinguir fatos de opiniões
				Sarcasmo e ironias
				Uso de pronomes para referenciar itens
				Uso de termos informais na internet
				Uso de memes
				Uso de emoticons
			Etapas:
				1) Coleta do conteúdo (obtenção dos dados)
				2) Classificação do sentimento relacionado ao conteúdo avaliado (positivo, negativo e neutro)
				3) Sumarização dos resultados

		Métodos ensembles
			Dividir para conquistar.
			Objetivos:
				Classificar os dados de entrada em diferentes classificadores com diferentes pesos afim de se obter um resultado final através da combinação dos resultados dos classificadores com seus respectivos pesos.
			Etapas:
				1) Enviar os dados de entrada a cada classificador
				2) Classificação
				3) Resultados são enviados para um combinador que dará um resultado finalúnico baseado nas clsasificações feitas e seus respectivos pesos
			Razões de utilização:
				Bom desempenho no treinamento não garante um bom desempenho na generalização
				Não seguir a recomendação de um especialista
				O volume de dados a ser analisado pode ser muito grande para um único classificador
				Alternativa para criação de classificadores mais precisos.	
			Pode aumentar o tempo de processamento por causa do aumento de classificadores.

	##### Capítulo 3 - Redes neurais

		As redes neurais artificiais (RNAs) são  modelos matemáticos que se assemelham as estruturas neurais biológicas e que tem capacidade computacional adiquirida por meio de aprendizado e generalização.
		O aprendizado em RNA está normalmente associado à capacidade que elas possuem de adaptarem seus parâmetros como consequência de sua interação com o meio externo.
		Os critérios de desempenho que podem determinar a qualidade do modelo neural e o ponto de parada dos treinamentos são determinados por meio dos parÂmetros utilizados no treinamento da rede neural.
		A generalização de uma rede está relacionada à capacidade que esta rede tem em promover respostas coerentes para os dados utilizados como entrada em seu treinamento.
		As informações em RNAs fluem através de estruturas neurais artificiais, onde o processamento é feito de forma paralela e distribuida (dimensões).
		A estrutura de processamento de uma rede neural é o neurônio artificial que tem como entrada de dados um vetor, de dimensão p, formado de tuplas contendo variável x e seu respectivo peso w. A soma das váriaveis de entrada x ponderadas pelos seus pessos correspondentes w, é chamada de saída linear u. A saída de um neurônio artificial y é chamada de saída de ativação, esta pode ser obtida pela aplicação da função de ativação à saída linear. A função de ativação pode assumir várias formas geralemente não lineares. Exmplo: função de grau unipolar (limite).
		As RNAs têm a capacidade de aprendizado por meio de exemplos e também por meio de extrapolações e interpolações em cima do que elas já aprenderam.
		Algoritimo de aprendizagem:
			Conjunto de procedimentos definidos para adaptação dos parâmetros de uma RNA para que esta tenha a capacidade de aprender uma função específica.
			Os métodos de treinamento podem ser supervisionados ou não.

		Tipos de rede:
			1) Pereceptron de uma camada: 
				Só possue uma dimensão ou camada, utilizada para dividir duas classes linearmente separáveis. Apresenta erro para classes não linearmente separáveis. 
				O resultado da somatória das entradas ponderadas é somado ao limiar de ativação O e repassado a função de ativação que terá a saída y. 
				Tipo de função bipolar ou degrau normalmente.
			2) Redes de múltiplas camadas (MPL - Multilayer Perceptron):
				Formadas por um conjunto de nós sensoriais ou fontes (receptores de informações), um conjunto de nós computacionais (camadas ocultas) e um conjunto de nós de saída. Generalização do perceptron de uma camada. 
				Trata dados não linearmente separáveis.
				O uso de uma grande quantidade de camadas não é indicado pois o erro ocorrido em uma camada é propagado para as outras.
				O uso excessivo de neurônios pode levar a memorização dos dados de treinamento ao invés da generalização.
				O uso de poucos neurônios poderá levar a rede a aumentar o tempo de treinamento e com isso dificultar a ótima representação do problema proposto. 
				Pode ser feedfoward aonde as camadas são acionadas de forma ordenada da entrada a saída da rede, ou backpropagation (retropropagation) que propaga os erros para os neuronio que foram acionados para o seu cálculo no sentido inverso das camadas
			3) Redes Neurais de Hopfield:
				Consiste em um conjunto de neurônios e um conjunto correspondente de atrasos unitários, formando um sistema realimentado de múltiplos laços. A saída de cada neurônio é realimentada através de um atraso unitário para cada um dos outros neurônios na rede.
				Não há autoalimentação.
				Podem ser usadas como memórias associativas, nas quais a rede pode armazenar informações baseadas em alguns de seus estados.
				Podem resolver problemas de análise combinatória.

		Deep Learning - Redes convolucionais (RNCs)
			Conjunto de algoritimos que tentam modelar abstrações de alto nível de dados usando um garfo profundo várias camadas de processamento.
			Permite lidar com problemas que envolvem transformações lineares ou não lineares.
			Inspiradas no sistema de visão humana.
			Recebe como entrada pequenas porções de imagens , na camada mais baixa da estrutura hierárquica. A arquitetura mais complexa permite estabilidade mesmo com alterações em relação a escala ou rotação.
			Técnica mais utilizada:
				Convolutional neural networks - Utilizada oara processamento de imagens, detecção de caracteres escritos a mão e leitura de texto.
			Exemplos de uso:
				1) Reconhecimento facial
				2) Classificação de doenças,
				3) Carros autônomos,
				4) Visão computacional
				5) Processamento de linguagem natural, etc.

	##### Capítulo 4 - Algoritimos de machine learning

		Árvores de decisão
			Definição:
				Modelos estatísticos que utilizam um treinamento supervisionado para a classificação e previsão de dados.
				Um problema complexo é decomposto em subproblemas mais simples e recursivamente esta técnica é aplicada a cada subproblema.
				Pode-se extrair regras se-então que são facilmente compreendidas.
				A capacidade de discriminação de uma árvore vem da divisão do espaço pelos atributos em subespaços e cada subespaço é associado a uma classe.
				Em uma árvore de decisão cada nó conteém um teste de atributo, cada ramo corresponde a um possível valor deste atributo, cada nó-folha está assiciado a uma classe e cada percurso da árvore (raiz até folha) corresponde a uma regra de classificação.
			Paradigmas dos modelos computacionais de classificação:
				1) Top-down
					Obtenção do modelo de classificação a partir de informações fornecidas por especialistas
				2) Bottom-up
					Obtenção de modelo de classificaçã ela identificação de relacionamentos entre variáveis dependentes e independentes em bases de dados rotulados. 
					O classificador é induzido por mecanismos de generalização fundamentados em exemplos específicos (Conjunto finitos de objetos rotulados).
					Existem propostas também para dados não rotulados.
			Exemplos de utilização:
				1) Risco de crédito
				2) Diagnóstico médico
				3) Decisões de compra e venda
				4) Diagnóstico de problemas em equipamentos
			Entropia
				Definição: 
					Cálculo do ganho de informação baseado em uma medida utilizada na teoria da infomação.
					Valor de 0 a 1. 
					Quanto maior a proximidade de 1, maior  a entropia e a e a heterogenização dos dados.
					Caracteriza a impureza dos dados: Medida da falta de homoegneidade dos dados de entrada em relação a sua classificação.
			Objetivos da construção de uma árvore de decisão:
				1) Diminuir a entropia (a aleatoriedade da variável objetivo).
				2) Ser consistente com o conjunto de dados.
				3) Possuir o menor número de nós. 
			Principais algoritimos:
				1) ID3 (cursivo e baseado em busca exaustiva)
				2) C4.5 (usa técnica dividir para conquistar)

		SVM - Suport Vector Machine
			Definição:
				Método de aprendizado que tenta encontrar a maior margem para separar duas classes diferentes de dados em um espaço de amostragem.
				Método supervisionado de classificação binária (somente duas classes). Para utilizar em múltiplas classes é necessário transformar o problema em vários de classe binária.
				Abordagem geométrica para o problema de classificação onde cada contexto do conunto de treinamento pode ser visto como um ponto x em um espaço r. O aprendizado consiste em dividir os elementos ositivos e negativos nesse espaço euclidiano.
				Método linear de classificação.
			Exemplos de utilização:
				1) Reconhecimento de padrões.
				2) Categorização de textos
			Principais características:
				1) Boa capacidade de generalização (sem overfitting).
				2) Robustez em grandes dimensões (objetos de grandes dimensões como imagens
			Problemas comuns:
				1) Outliers 
				2) Exemplos rotulados erroneamente

		KNN - K-Nearest Neighbours
			Definição:
				Realiza a classficiação de um novo objeto baseado nos vizinhos mais próximos. O núcleo de seu funcionamento está em descobrir os k vizinhos mais próximos de uma determinada instância e classifica-la conforme a classificação da maioria de seus vizinhos.
				Para sua utilização é necessário um conjunto de exemplos de treinamento, a definição de uma métrica para calcular a distância entre os exemplos de treinamento e a definição de k.
				Método de aprendizado supervisionado.
			Exemplos de utilização:
				1) Reconhecimento de padrões.

		Naive Bayes
			Definição:
				Método de aprendizado supervisionado.
				Desconsidera completamente a correlação entre as veriáveis (features) dos objetos.
				Muito utilizado quando a o conjunto de treinamento é grande ou moderado e os atributos (features) descrevem as classes de forma independente.
				Muito simple, rápido e de desempenho maior que a maioria dos classficiadores.
				Para cada classe do modelo são calculadas as probabilidades de pertencimento a esta de acordo com cada valor possível característica individualmente de forma que a probabilidade final de pertencimento a uma classe se da pela maior probabilidade individual encontrada.
			Exemplos de utilização:
			Categoriazar textos baseados na frequência das palavras usadas.